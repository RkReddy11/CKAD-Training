In Kubernetes, a rolling update strategy is a mechanism used to update or upgrade a deployment or a set of pods in a controlled and gradual manner. It ensures that the application remains available during the update process by replacing pods gradually, one at a time, while maintaining a desired number of replicas.

Let's understand the rolling update strategy with an example:

Suppose you have a deployment named myapp-deployment with three replicas running a web application. You want to update the application to a new version without causing any downtime. Here's how you can achieve this using a rolling update strategy:

Prepare the updated version:
Build and push the updated version of your application to a container registry. This new version could include bug fixes, feature enhancements, or configuration changes.

Update the Deployment:
Modify the deployment configuration to use the new version of the container image. This triggers the rolling update process. Here's an example of a deployment configuration:

apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
        - name: myapp-container
          image: myapp-image:v2
In this example, the image field is updated to myapp-image:v2, which represents the new version of the application. The deployment configuration also specifies that there should be three replicas of the updated application.

Rolling Update Process:
Kubernetes manages the rolling update process automatically based on the configuration. It starts by creating new pods with the updated version while keeping the old pods running. The new pods are gradually introduced into the cluster, and the old pods are gradually terminated.

During the rolling update, Kubernetes ensures that the desired number of replicas (in this case, three) is maintained at all times. It carefully manages the replacement of pods to avoid any downtime.

Validation and Rollback:
After completing the rolling update, you can perform validations to ensure the new version is running correctly. If any issues are detected, you can roll back the deployment to the previous version by updating the deployment configuration again.

By using the rolling update strategy, you can safely update your applications without impacting availability. Kubernetes manages the process by gradually replacing old pods with new ones, ensuring a smooth transition and minimizing disruption.

It's important to note that the rolling update strategy can be further customized by adjusting parameters such as the update strategy, max surge, and max unavailable. These parameters control the speed and behavior of the rolling update process, allowing you to fine-tune the update process based on your specific requirements.

Overall, the rolling update strategy in Kubernetes provides a controlled and seamless approach to updating your applications while maintaining high availability and minimizing downtime.


Creating a deployment, checking the rollout status and history:

In the example below, we will first create a simple deployment and inspect the rollout status and the rollout history:



master $ kubectl create deployment nginx --image=nginx:1.16
deployment.apps/nginx created
 
master $ kubectl rollout status deployment nginx
Waiting for deployment "nginx" rollout to finish: 0 of 1 updated replicas are available...
deployment "nginx" successfully rolled out
 
master $
 
 
master $ kubectl rollout history deployment nginx
deployment.extensions/nginx
REVISION CHANGE-CAUSE
1     <none>
 
master $


Using the --revision flag:

Here the revision 1 is the first version where the deployment was created.

You can check the status of each revision individually by using the --revision flag:

master $ kubectl rollout history deployment nginx --revision=1
deployment.extensions/nginx with revision #1
 
Pod Template:
 Labels:    app=nginx    pod-template-hash=6454457cdb
 Containers:  nginx:  Image:   nginx:1.16
  Port:    <none>
  Host Port: <none>
  Environment:    <none>
  Mounts:   <none>
 Volumes:   <none>
master $ 


Using the --record flag:

You would have noticed that the "change-cause" field is empty in the rollout history output. We can use the --record flag to save the command used to create/update a deployment against the revision number.

master $ kubectl set image deployment nginx nginx=nginx:1.17 --record
deployment.extensions/nginx image updated
master $master $
 
master $ kubectl rollout history deployment nginx
deployment.extensions/nginx
 
REVISION CHANGE-CAUSE
1     <none>
2     kubectl set image deployment nginx nginx=nginx:1.17 --record=true
master $


You can now see that the change-cause is recorded for the revision 2 of this deployment.

Let's make some more changes. In the example below, we are editing the deployment and changing the image from nginx:1.17 to nginx:latest while making use of the --record flag.

master $ kubectl edit deployments. nginx --record
deployment.extensions/nginx edited
 
master $ kubectl rollout history deployment nginx
REVISION CHANGE-CAUSE
1     <none>
2     kubectl set image deployment nginx nginx=nginx:1.17 --record=true
3     kubectl edit deployments. nginx --record=true
 
 
 
master $ kubectl rollout history deployment nginx --revision=3
deployment.extensions/nginx with revision #3
 
Pod Template: Labels:    app=nginx
    pod-template-hash=df6487dc Annotations: kubernetes.io/change-cause: kubectl edit deployments. nginx --record=true
 
 Containers:
  nginx:
  Image:   nginx:latest
  Port:    <none>
  Host Port: <none>
  Environment:    <none>
  Mounts:   <none>
 Volumes:   <none>
 
master $


Undo a change:

Lets now rollback to the previous revision:

controlplane $ kubectl rollout history deployment nginx
deployment.apps/nginx 
REVISION  CHANGE-CAUSE
1         <none>
3         kubectl edit deployments.apps nginx --record=true
4         kubectl set image deployment nginx nginx=nginx:1.17 --record=true
 
 
 
controlplane $ kubectl rollout history deployment nginx --revision=3
deployment.apps/nginx with revision #3
Pod Template:
  Labels:       app=nginx
        pod-template-hash=787f54657b
  Annotations:  kubernetes.io/change-cause: kubectl edit deployments.apps nginx --record=true
  Containers:
   nginx:
    Image:      nginx:latest
    Port:      <none> 
    Host Port:  <none>
    Environment: <none>       
    Mounts:     <none>
  Volumes:      
 
controlplane $ kubectl describe deployments. nginx | grep -i image:
    Image:        nginx:1.17
 
controlplane $


With this, we have rolled back to the previous version of the deployment with the image = nginx:1.17.

controlplane $ kubectl rollout history deployment nginx --revision=1
deployment.apps/nginx with revision #1
Pod Template:
  Labels:       app=nginx
        pod-template-hash=78449c65d4
  Containers:
   nginx:
    Image:      nginx:1.16
    Port:       <none> 
    Host Port:  <none>
    Environment: <none>     
    Mounts:     <none>
  Volumes:      
 
controlplane $ kubectl rollout undo deployment nginx --to-revision=1
deployment.apps/nginx rolled back
To rollback to specific revision we will use the --to-revision flag.
With --to-revision=1, it will be rolled back with the first image we used to create a deployment as we can see in the rollout history output.

controlplane $ kubectl describe deployments. nginx | grep -i image:
Image: nginx:1.16
